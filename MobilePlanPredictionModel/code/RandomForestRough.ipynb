{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plan\n",
      "1    1985\n",
      "2    2978\n",
      "3    4368\n",
      "4    5559\n",
      "5    2978\n",
      "6    1389\n",
      "7     595\n",
      "dtype: int64\n",
      "[2 3 2 ... 2 2 6]\n",
      "0.936036262906069\n",
      "[[383   4   0   0   0   0   0]\n",
      " [ 31 538   0   0   0   0   0]\n",
      " [  0   2 890  16   0   0   0]\n",
      " [  0   0 124 977   0   0   0]\n",
      " [  0   0   0  62 548   0   0]\n",
      " [  0   0   0   1   4 276   0]\n",
      " [  0   0   0   0   0  10 105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.99      0.96       387\n",
      "           2       0.99      0.95      0.97       569\n",
      "           3       0.88      0.98      0.93       908\n",
      "           4       0.93      0.89      0.91      1101\n",
      "           5       0.99      0.90      0.94       610\n",
      "           6       0.97      0.98      0.97       281\n",
      "           7       1.00      0.91      0.95       115\n",
      "\n",
      "    accuracy                           0.94      3971\n",
      "   macro avg       0.95      0.94      0.95      3971\n",
      "weighted avg       0.94      0.94      0.94      3971\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "# Read CSV file and import the data as DataFrame\n",
    "filename = \"E:\\\\Work\\\\github\\\\mtech\\\\FinalSemProject\\\\data\\\\record_second.csv\"\n",
    "names = ['name', 'address', 'phoneNumber', 'region','age', 'callCount', 'activeCallTime', \n",
    "         'smsCount', 'dataUsage', 'Subscription_1', 'Subscription_2', \n",
    "         'Subscription_3', 'Subscription_4', 'plan']\n",
    "dataset = pd.read_csv(filename, names=names)\n",
    "\n",
    "# The below values are scrapped since they do not contribute to the prediction\n",
    "dataset.pop('name')\n",
    "dataset.pop('address')\n",
    "dataset.pop('phoneNumber')\n",
    "\n",
    "#print(dataset.describe())\n",
    "print(dataset.groupby('plan').size())\n",
    "\n",
    "def descritize(column_name, num_of_bins):\n",
    "    data = dataset[column_name].values\n",
    "    df = pd.DataFrame(data,columns=[column_name])\n",
    "    trans = KBinsDiscretizer(n_bins=num_of_bins, encode='ordinal', strategy='uniform')\n",
    "    data = trans.fit_transform(df)\n",
    "    return pd.DataFrame(data)\n",
    "        \n",
    "        \n",
    "# To convert the string to number. Here city names are converted to integer.\n",
    "le = LabelEncoder()\n",
    "for col in dataset.columns:\n",
    "    \n",
    "    if col == 'region':\n",
    "        dataset[col] = LabelEncoder().fit_transform(dataset[col])\n",
    "\n",
    "array = dataset.values\n",
    "x = array[:,0:9]\n",
    "y = array[:,10]\n",
    "\n",
    "# Splitting the dataset into training and test set.  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.20, random_state=0)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "classifier= RandomForestClassifier(n_estimators= 100, criterion=\"entropy\")  \n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred= classifier.predict(x_test)  \n",
    "print(y_pred)\n",
    "\n",
    "#model = RandomForestClassifier(n_estimators= 10, criterion=\"entropy\")\n",
    "#model.fit(x_train, x_train)\n",
    "#predictions = model.predict(x_test)\n",
    "# Evaluate predictions\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Model Analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramji\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.551436 (0.010582)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramji\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n",
      "C:\\Users\\Ramji\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  \n",
      "C:\\Users\\Ramji\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: 0.546089 (0.007541)\n",
      "KNN: 0.598727 (0.010498)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramji\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART: 0.779693 (0.008480)\n",
      "NB: 0.546524 (0.013320)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramji\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n",
      "C:\\Users\\Ramji\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "One reason to discretize continuous features is to improve \n",
    "signal-to-noise ratio. Fitting a model to bins reduces the \n",
    "impact that small fluctuates in the data has on the model, \n",
    "often small fluctuates are just noise. Each bin \"smooths\" \n",
    "out the fluctuates/noises in sections of the data.\n",
    "'''\n",
    "\n",
    "from pandas import read_csv\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "url = \"E:\\\\Work\\\\github\\\\mtech\\\\FinalSemProject\\\\data\\\\record_second.csv\"\n",
    "names = ['name', 'address', 'phoneNumber', 'region','age', 'callCount', 'activeCallTime', \n",
    "         'smsCount', 'dataUsage', 'Subscription_1', 'Subscription_2', \n",
    "         'Subscription_3', 'Subscription_4', 'plan']\n",
    "dataset = read_csv(url, names=names)\n",
    "\n",
    "#print(dataset.info())\n",
    "#print(dataset.describe())\n",
    "\n",
    "'''\n",
    "The below command can be used to find the unique elements in the data set,\n",
    "which can be eliminated for further processing\n",
    "'''\n",
    "\n",
    "dataset.pop('name')\n",
    "dataset.pop('address')\n",
    "dataset.pop('phoneNumber')\n",
    "#dataset.pop('region')\n",
    "\n",
    "#print(dataset.describe(include=np.object))\n",
    "\n",
    "#print(dataset.groupby('plan').size())\n",
    "\n",
    "#dataset.plot(kind='box', subplots=True, layout=(5,2), sharex=False, sharey=False)\n",
    "#pyplot.show()\n",
    "\n",
    "\n",
    "#dataset.hist()\n",
    "'''\n",
    "fig, axes = pyplot.subplots(figsize=(19,10), dpi=50, nrows=3, ncols=4)\n",
    "flat_axes = list(axes.reshape(-1))\n",
    "fig.delaxes(flat_axes.pop(-1))\n",
    "fig.delaxes(flat_axes.pop(-1))\n",
    "\n",
    "dataset.hist(ax=flat_axes, alpha=0.5, label='x',color='b')\n",
    "\n",
    "pyplot.plot()\n",
    "'''\n",
    "le = LabelEncoder()\n",
    "\n",
    "\n",
    "df = dataset[dataset.columns[:]].apply(le.fit_transform)\n",
    "\n",
    "array = df.values\n",
    "X = array[:,0:9]\n",
    "y = array[:,10]\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=0.20, random_state=1, shuffle=True)\n",
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators= 10, criterion=\"entropy\")))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "print(\"Start Model Analysis...\")\n",
    "for name, model in models:\n",
    "\tkfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\tcv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\n",
    "\n",
    "print(\"Completed Model Analysis...\")\n",
    "# Compare Algorithms\n",
    "pyplot.boxplot(results, labels=names)\n",
    "pyplot.title('Algorithm Comparison')\n",
    "pyplot.show()\n",
    "\n",
    "model = RandomForestClassifier(n_estimators= 10, criterion=\"entropy\")\n",
    "model.fit(X_train, Y_train)\n",
    "predictions = model.predict(X_validation)\n",
    "# Evaluate predictions\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plan\n",
      "1       1985\n",
      "2       2978\n",
      "3       4368\n",
      "4       5559\n",
      "5       2978\n",
      "6       1389\n",
      "7        595\n",
      "plan       1\n",
      "dtype: int64\n",
      "[[8 '20' '2' '9' '10' '24' '0' '0' '0']\n",
      " [8 '30' '18' '18' '8' '721' '0' '0' '0']\n",
      " [1 '20' '7' '10' '1' '4' '0' '0' '0']\n",
      " [2 '31' '5' '20' '17' '448' '0' '0' '0']\n",
      " [1 '18' '4' '4' '0' '15' '0' '0' '0']\n",
      " [8 '33' '16' '22' '10' '259' '0' '0' '0']\n",
      " [9 '68' '3' '10' '2' '28' '0' '0' '0']\n",
      " [0 '33' '27' '27' '46' '2736' '0' '0' '1']\n",
      " [4 '37' '16' '22' '20' '1465' '0' '1' '0']\n",
      " [9 '65' '13' '23' '9' '651' '0' '0' '0']\n",
      " [3 '69' '4' '6' '6' '25' '0' '0' '0']\n",
      " [4 '49' '11' '11' '10' '408' '0' '0' '0']\n",
      " [3 '76' '5' '13' '20' '168' '0' '0' '0']\n",
      " [3 '81' '4' '14' '4' '13' '0' '0' '0']\n",
      " [2 '33' '6' '21' '18' '313' '0' '0' '0']\n",
      " [6 '38' '17' '25' '7' '604' '0' '0' '0']\n",
      " [0 '31' '13' '13' '9' '183' '0' '0' '0']\n",
      " [2 '59' '5' '16' '5' '25' '0' '0' '0']\n",
      " [4 '52' '4' '13' '1' '25' '0' '0' '0']\n",
      " [0 '73' '8' '19' '18' '886' '0' '0' '0']]\n",
      "['2' '4' '2' '3' '2' '4' '2' '6' '6' '4' '2' '3' '3' '2' '4' '4' '3' '2'\n",
      " '2' '4']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'subscription_c'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7ab8ce03aedb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"entropy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[0mlow_limit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    431\u001b[0m         \u001b[0monly\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mits\u001b[0m \u001b[0mindices\u001b[0m \u001b[0mare\u001b[0m \u001b[0mstored\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0ma\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mbit\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m         \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mversionadded\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.20\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;34m'numeric'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'numeric'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'subscription_c'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from sklearn.preprocessing import KBinsDiscretizer\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "# Read CSV file and import the data as DataFrame\n",
    "filename = \"E:\\\\Work\\\\github\\\\mtech\\\\FinalSemProject\\\\data\\\\record_second.csv\"\n",
    "names = ['name', 'address', 'phoneNumber', 'region','age', 'callCount', 'activeCallTime', \n",
    "         'smsCount', 'dataUsage', 'Subscription_1', 'Subscription_2', \n",
    "         'Subscription_3', 'Subscription_4', 'plan']\n",
    "dataset = pd.read_csv(filename, names=names)\n",
    "\n",
    "# The below values are scrapped since they do not contribute to the prediction\n",
    "dataset.pop('name')\n",
    "dataset.pop('address')\n",
    "dataset.pop('phoneNumber')\n",
    "\n",
    "#print(dataset.describe())\n",
    "print(dataset.groupby('plan').size())\n",
    "\n",
    "def descritize(column_name, num_of_bins):\n",
    "    data = dataset[column_name].values\n",
    "    df = pd.DataFrame(data,columns=[column_name])\n",
    "    trans = KBinsDiscretizer(n_bins=num_of_bins, encode='ordinal', strategy='uniform')\n",
    "    data = trans.fit_transform(df)\n",
    "    return pd.DataFrame(data)\n",
    "        \n",
    "        \n",
    "# To convert the string to number. Here city names are converted to integer.\n",
    "le = LabelEncoder()\n",
    "for col in dataset.columns:\n",
    "    \n",
    "    if col == 'region':\n",
    "        dataset[col] = LabelEncoder().fit_transform(dataset[col])\n",
    "\n",
    "array = dataset.values\n",
    "x = array[:,0:9]\n",
    "y = array[:,10]\n",
    "\n",
    "# Splitting the dataset into training and test set.  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.25, random_state=0)  \n",
    "\n",
    "print(x_test[0:20])\n",
    "print(y_test[0:20])\n",
    "\n",
    "'''\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "classifier= RandomForestClassifier(n_estimators= 100, criterion=\"entropy\")  \n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred= classifier.predict(x_test) \n",
    "print(y_pred)\n",
    "\n",
    "#model = RandomForestClassifier(n_estimators= 10, criterion=\"entropy\")\n",
    "#model.fit(x_train, x_train)\n",
    "#predictions = model.predict(x_test)\n",
    "# Evaluate predictions\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "'''\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "classifier= RandomForestClassifier(n_estimators= 100, criterion=\"entropy\")  \n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "low_limit = 0\n",
    "upper_limit = 1\n",
    "for i in range(20):\n",
    "    y_pred= classifier.predict(x_test[low_limit:upper_limit])\n",
    "    #print(y_pred)\n",
    "    if(y_pred != y_test[low_limit:upper_limit]):\n",
    "        print(\"upper_limit: \", upper_limit, y_pred)\n",
    "       \n",
    "    low_limit = low_limit + 1\n",
    "    upper_limit = upper_limit + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

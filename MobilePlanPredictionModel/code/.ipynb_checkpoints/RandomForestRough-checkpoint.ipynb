{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plan\n",
      "1    1985\n",
      "2    2978\n",
      "3    4368\n",
      "4    5559\n",
      "5    2978\n",
      "6    1389\n",
      "7     595\n",
      "dtype: int64\n",
      "[2 3 2 ... 2 2 6]\n",
      "0.936036262906069\n",
      "[[383   4   0   0   0   0   0]\n",
      " [ 31 538   0   0   0   0   0]\n",
      " [  0   2 890  16   0   0   0]\n",
      " [  0   0 124 977   0   0   0]\n",
      " [  0   0   0  62 548   0   0]\n",
      " [  0   0   0   1   4 276   0]\n",
      " [  0   0   0   0   0  10 105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.99      0.96       387\n",
      "           2       0.99      0.95      0.97       569\n",
      "           3       0.88      0.98      0.93       908\n",
      "           4       0.93      0.89      0.91      1101\n",
      "           5       0.99      0.90      0.94       610\n",
      "           6       0.97      0.98      0.97       281\n",
      "           7       1.00      0.91      0.95       115\n",
      "\n",
      "    accuracy                           0.94      3971\n",
      "   macro avg       0.95      0.94      0.95      3971\n",
      "weighted avg       0.94      0.94      0.94      3971\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "# Read CSV file and import the data as DataFrame\n",
    "filename = \"E:\\\\Work\\\\github\\\\mtech\\\\FinalSemProject\\\\data\\\\record_second.csv\"\n",
    "names = ['name', 'address', 'phoneNumber', 'region','age', 'callCount', 'activeCallTime', \n",
    "         'smsCount', 'dataUsage', 'Subscription_1', 'Subscription_2', \n",
    "         'Subscription_3', 'Subscription_4', 'plan']\n",
    "dataset = pd.read_csv(filename, names=names)\n",
    "\n",
    "# The below values are scrapped since they do not contribute to the prediction\n",
    "dataset.pop('name')\n",
    "dataset.pop('address')\n",
    "dataset.pop('phoneNumber')\n",
    "\n",
    "#print(dataset.describe())\n",
    "print(dataset.groupby('plan').size())\n",
    "\n",
    "def descritize(column_name, num_of_bins):\n",
    "    data = dataset[column_name].values\n",
    "    df = pd.DataFrame(data,columns=[column_name])\n",
    "    trans = KBinsDiscretizer(n_bins=num_of_bins, encode='ordinal', strategy='uniform')\n",
    "    data = trans.fit_transform(df)\n",
    "    return pd.DataFrame(data)\n",
    "        \n",
    "        \n",
    "# To convert the string to number. Here city names are converted to integer.\n",
    "le = LabelEncoder()\n",
    "for col in dataset.columns:\n",
    "    \n",
    "    if col == 'region':\n",
    "        dataset[col] = LabelEncoder().fit_transform(dataset[col])\n",
    "\n",
    "array = dataset.values\n",
    "x = array[:,0:9]\n",
    "y = array[:,10]\n",
    "\n",
    "# Splitting the dataset into training and test set.  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.20, random_state=0)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "classifier= RandomForestClassifier(n_estimators= 100, criterion=\"entropy\")  \n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred= classifier.predict(x_test)  \n",
    "print(y_pred)\n",
    "\n",
    "#model = RandomForestClassifier(n_estimators= 10, criterion=\"entropy\")\n",
    "#model.fit(x_train, x_train)\n",
    "#predictions = model.predict(x_test)\n",
    "# Evaluate predictions\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Model Analysis...\n",
      "LR: 0.738427 (0.008888)\n",
      "LDA: 0.778731 (0.008990)\n",
      "KNN: 0.829297 (0.008276)\n",
      "CART: 0.898364 (0.006277)\n",
      "NB: 0.854861 (0.005994)\n",
      "SVM: 0.411750 (0.005256)\n",
      "RF: 0.933632 (0.005562)\n",
      "Completed Model Analysis...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9309997481742635\n",
      "[[408   4   0   0   0   0   0]\n",
      " [ 31 588   0   0   0   0   0]\n",
      " [  0   1 850  18   0   0   0]\n",
      " [  0   0 131 990   2   0   0]\n",
      " [  0   0   0  60 491   0   0]\n",
      " [  0   0   0   3  10 264   0]\n",
      " [  0   0   0   0   0  14 106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       412\n",
      "           1       0.99      0.95      0.97       619\n",
      "           2       0.87      0.98      0.92       869\n",
      "           3       0.92      0.88      0.90      1123\n",
      "           4       0.98      0.89      0.93       551\n",
      "           5       0.95      0.95      0.95       277\n",
      "           6       1.00      0.88      0.94       120\n",
      "\n",
      "    accuracy                           0.93      3971\n",
      "   macro avg       0.95      0.93      0.94      3971\n",
      "weighted avg       0.93      0.93      0.93      3971\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "One reason to discretize continuous features is to improve \n",
    "signal-to-noise ratio. Fitting a model to bins reduces the \n",
    "impact that small fluctuates in the data has on the model, \n",
    "often small fluctuates are just noise. Each bin \"smooths\" \n",
    "out the fluctuates/noises in sections of the data.\n",
    "'''\n",
    "\n",
    "from pandas import read_csv\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "url = \"E:\\\\Work\\\\github\\\\mtech\\\\FinalSemProject\\\\data\\\\record_second.csv\"\n",
    "names = ['name', 'address', 'phoneNumber', 'region','age', 'callCount', 'activeCallTime', \n",
    "         'smsCount', 'dataUsage', 'Subscription_1', 'Subscription_2', \n",
    "         'Subscription_3', 'Subscription_4', 'plan']\n",
    "dataset = read_csv(url, names=names)\n",
    "\n",
    "#print(dataset.info())\n",
    "#print(dataset.describe())\n",
    "\n",
    "'''\n",
    "The below command can be used to find the unique elements in the data set,\n",
    "which can be eliminated for further processing\n",
    "'''\n",
    "\n",
    "dataset.pop('name')\n",
    "dataset.pop('address')\n",
    "dataset.pop('phoneNumber')\n",
    "#dataset.pop('region')\n",
    "\n",
    "#print(dataset.describe(include=np.object))\n",
    "\n",
    "#print(dataset.groupby('plan').size())\n",
    "\n",
    "#dataset.plot(kind='box', subplots=True, layout=(5,2), sharex=False, sharey=False)\n",
    "#pyplot.show()\n",
    "\n",
    "\n",
    "#dataset.hist()\n",
    "'''\n",
    "fig, axes = pyplot.subplots(figsize=(19,10), dpi=50, nrows=3, ncols=4)\n",
    "flat_axes = list(axes.reshape(-1))\n",
    "fig.delaxes(flat_axes.pop(-1))\n",
    "fig.delaxes(flat_axes.pop(-1))\n",
    "\n",
    "dataset.hist(ax=flat_axes, alpha=0.5, label='x',color='b')\n",
    "\n",
    "pyplot.plot()\n",
    "'''\n",
    "le = LabelEncoder()\n",
    "\n",
    "\n",
    "df = dataset[dataset.columns[:]].apply(le.fit_transform)\n",
    "\n",
    "array = df.values\n",
    "X = array[:,0:9]\n",
    "y = array[:,10]\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=0.20, random_state=1, shuffle=True)\n",
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators= 10, criterion=\"entropy\")))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "print(\"Start Model Analysis...\")\n",
    "for name, model in models:\n",
    "\tkfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\tcv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\n",
    "\n",
    "print(\"Completed Model Analysis...\")\n",
    "# Compare Algorithms\n",
    "pyplot.boxplot(results, labels=names)\n",
    "pyplot.title('Algorithm Comparison')\n",
    "pyplot.show()\n",
    "\n",
    "model = RandomForestClassifier(n_estimators= 10, criterion=\"entropy\")\n",
    "model.fit(X_train, Y_train)\n",
    "predictions = model.predict(X_validation)\n",
    "# Evaluate predictions\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plan\n",
      "1    1985\n",
      "2    2978\n",
      "3    4368\n",
      "4    5559\n",
      "5    2978\n",
      "6    1389\n",
      "7     595\n",
      "dtype: int64\n",
      "[[   1   63    4   16    8    4    0    0    0]\n",
      " [   7   64    6   14    8  272    0    0    0]\n",
      " [   9   30    6    8    0   36    0    0    0]\n",
      " [   1   76    5   13    2  464    0    0    0]\n",
      " [   2   18    6    6    0   18    0    0    0]\n",
      " [   9   43    7   14   24  365    0    0    0]\n",
      " [   8   40    9   16    1   33    0    0    0]\n",
      " [   0   25   10   28   26 2688    0    1    0]\n",
      " [   1   35   10   21   23 2141    0    1    0]\n",
      " [   3   39   13   21   25  379    0    0    0]\n",
      " [   9   20    7   15    4   26    0    0    0]\n",
      " [   7   55    7   12   17   65    0    0    0]\n",
      " [   7   54    6   15   19  492    0    0    0]\n",
      " [   7   50    6    8   11    0    0    0    0]\n",
      " [   1   19    7    9   10  334    0    0    0]\n",
      " [   6   65    6    9   16  594    0    0    0]\n",
      " [   0   51    8    9   16  229    0    0    0]\n",
      " [   8   52    4   11    9   48    0    0    0]\n",
      " [   3   77    2   10   12   19    0    0    0]\n",
      " [   2   51   13   21   11  711    0    0    0]]\n",
      "[2 4 2 3 2 4 2 6 6 4 2 3 3 2 4 4 3 2 2 4]\n",
      "upper_limit:  2 [3]\n",
      "upper_limit:  15 [3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "# Read CSV file and import the data as DataFrame\n",
    "filename = \"E:\\\\Work\\\\github\\\\mtech\\\\FinalSemProject\\\\data\\\\record_second.csv\"\n",
    "names = ['name', 'address', 'phoneNumber', 'region','age', 'callCount', 'activeCallTime', \n",
    "         'smsCount', 'dataUsage', 'Subscription_1', 'Subscription_2', \n",
    "         'Subscription_3', 'Subscription_4', 'plan']\n",
    "dataset = pd.read_csv(filename, names=names)\n",
    "\n",
    "# The below values are scrapped since they do not contribute to the prediction\n",
    "dataset.pop('name')\n",
    "dataset.pop('address')\n",
    "dataset.pop('phoneNumber')\n",
    "\n",
    "#print(dataset.describe())\n",
    "print(dataset.groupby('plan').size())\n",
    "\n",
    "def descritize(column_name, num_of_bins):\n",
    "    data = dataset[column_name].values\n",
    "    df = pd.DataFrame(data,columns=[column_name])\n",
    "    trans = KBinsDiscretizer(n_bins=num_of_bins, encode='ordinal', strategy='uniform')\n",
    "    data = trans.fit_transform(df)\n",
    "    return pd.DataFrame(data)\n",
    "        \n",
    "        \n",
    "# To convert the string to number. Here city names are converted to integer.\n",
    "le = LabelEncoder()\n",
    "for col in dataset.columns:\n",
    "    \n",
    "    if col == 'region':\n",
    "        dataset[col] = LabelEncoder().fit_transform(dataset[col])\n",
    "\n",
    "array = dataset.values\n",
    "x = array[:,0:9]\n",
    "y = array[:,10]\n",
    "\n",
    "# Splitting the dataset into training and test set.  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.25, random_state=0)  \n",
    "\n",
    "print(x_test[0:20])\n",
    "print(y_test[0:20])\n",
    "\n",
    "'''\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "classifier= RandomForestClassifier(n_estimators= 100, criterion=\"entropy\")  \n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred= classifier.predict(x_test) \n",
    "print(y_pred)\n",
    "\n",
    "#model = RandomForestClassifier(n_estimators= 10, criterion=\"entropy\")\n",
    "#model.fit(x_train, x_train)\n",
    "#predictions = model.predict(x_test)\n",
    "# Evaluate predictions\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "'''\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "classifier= RandomForestClassifier(n_estimators= 100, criterion=\"entropy\")  \n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "low_limit = 0\n",
    "upper_limit = 1\n",
    "for i in range(20):\n",
    "    y_pred= classifier.predict(x_test[low_limit:upper_limit])\n",
    "    #print(y_pred)\n",
    "    if(y_pred != y_test[low_limit:upper_limit]):\n",
    "        print(\"upper_limit: \", upper_limit, y_pred)\n",
    "       \n",
    "    low_limit = low_limit + 1\n",
    "    upper_limit = upper_limit + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
